### Love Spider

#### 1. 部署环境
服务器要求：ubuntu 22.04  
Python环境：3.8  
Pillow >= 8.1

#### 2. 下载与安装
克隆仓库：
```bash
git clone https://github.com/2904202165/LoveSpider.git
```
安装:
```bash
Scrapy：pip install scrapy
```
安装依赖：
```bash
pip install -r requirements.txt
```

#### 3. 连续获取一个或多个微博关键词搜索结果：
**搜索正文中包含指定关键词的微博**，可以指定搜索的时间范围。
举个栗子，比如你可以搜索包含关键词“再见爱人”且发布日期在2024-11-25和2024-11-27之间的微博。搜索结果数量巨大，对于非常热门的关键词，在一天的指定时间范围，可以获得**1000万**以上的搜索结果。注意这里的一天指的是时间筛选范围，具体多长时间将这1000万微博下载到本地还要看获取的速度。1000万只是一天时间范围可获取的微博数量，如果想获取更多微博，可以加大时间范围，比如10天，最多可以获得1000万X10=1亿条搜索结果，当然你也可以再加大时间范围。对于大多数关键词，微博一天产生的相关搜索结果应该低于1000万，因此可以说**本程序可以获取指定关键词的全部或近似全部的搜索结果**。本程序可以获得几乎全部的微博信息，如微博正文、发布者等。

#### 4. 运行程序
运行命令：
```bash
scrapy crawl search -s JOBDIR=crawls/search
```
